\section{Container configuration}

Als we Docker containers gebruiken moeten de containers zelf ook goed geconfigureerd zijn. Een groot deel van de veiligheid van de containers zelf hangt af van hoe we ons ´docker run´ commando gebruiken. Daarnaast zijn er ook nog een aantal punten waarvoor we moeten oppassen of kunnen optimaliseren op de container zelf.

\subsection{docker run commando configureren}

Elke container word opgestart met het commando ´docker run [OPTIONS] IMAGE [COMMAND] [ARG...]´. Met dit commando kunnen aan de hand van onze zelfgemaakt Docker image of een gedownloade Docker image een container aanmaken en direct opstarten. Doordat dit een van de belangrijkste commando's is die bij Dokcer hoord is het uiteraard ook een van de krachtigste, dus moeten we wel beter enkele dingen in gedachten houden wanneer we het uitvoeren.

Bij het uitvoeren van het standaard ´docker run´ commando namelijk ´docker run IMAGE´ zijn er veel dingen die standaard in orde zijn. Uiteraard zijn er dingen waar we normaal geen problemen mee mogen hebben maar soms toch problemen kunnen veroorzaken.

Een van deze dingen zijn de standaard Linux Kernel Capabilities die de container heeft. Over Linux Kernel Capabilities zou kunnen een Bachelorproef op zich geschreven worden en gaat valt hierdoor niet binnen de scope van deze Bachelor proef. Maar sterk vereenvoudigd is dit de basis instructieset die een linux besturingssysteem bezit, deze instructies zijn als gewone gebruiker niet allemaal toegankelijk maar de root user kan elke instructie uitvoeren. Docker heeft uit voorzorg hiervoor deze lijst met Capabilities al sterk verminderd in vergelijking met de gewone Linux Kernel Capabilities, dit zorgt ervoor dat de root user in een container veel minder kan dan een root user op een gewoone machine. De meeste use cases hebben containers ook geen echte root rechten nodig. Hiervoor kunnen we dus de Linux Kernel Capabilities per container gaan tweaken en enkel privileges toewijzen aan de containers die ze echt nodig hebben. Om deze beperking te omzeilen kunnen Docker containers ook met de optie ´--privileged´ opstarten. Dit geeft de container alle Kernel Capabilities die het hostsysteem heeft en wordt dus best buiten in enkele zeer specifieke use cases vermeden.

Naast de mogelijkheid om de standaard Kernel Cabapilities aan te passen van de containers hebben we ook de mogelijkheid om het processor en geheugen gebruik te limiteren. Docker containers kunnen zonder verdere configuratie het complete geheugen gebruiken van de host, hierdoor kunnen andere containers zonder geheugen geraken en dit kan voor problemen zorgen. De mogelijkheid een container het complete geheugen van het hostsysteem in beslag neemt is zeker iets waar rekening mee gehouden moet worden. Hiervoor gebruiken we de optie ´-m´. Hiermee kunnen de maximale hoeveelheid geheugen die een container mag gebruiken bepalen. Een optie om de minimale hoeveelheid geheugen voor containers met een kritieke rol vast te leggen ontbreekt daarbij heelaas. Hierdoor kunnen deze kritieke containers ook zonder geheugen geraken waardoor de werking van ons systeem in gedrang komt. Een mogelijkheid om dit te vermijden zou kunnen zijn aan elke container een bepaalde hoeveelheid geheugen toewijzen waardoor als we de som maken van alle geheugengebruik we lager blijven dan de hoeveelheid geheugen van de host. Maar dan we moeten we elke keer als we een nieuwe container toevoegen elke container opnieuw opstarten met een andere hoeveelheid geheugen toegewezen. Hierdoor verliezen we onze flexibiliteit die we net verkijgen door docker te gebruiken en dit is dus niet aan te raden. Daarnaast hebben we ook CPU gebruik. Elke container gebruikt standaard een gelijke hoeveelheid van de cpu. De optie die gebruikt wordt om het cpu gebruik te bepalen is de ´-c´ of de cpu-shares optie. Standaard heeft deze een waarde van 1024, als alle containers deze waarde hebben, krijgen ze allemaal gelijke prioriteit op de cpu. Door deze waarde te verhogen of verlagen kunnen we desgewenst een hogere of lagere prioriteit verkrijgen voor onze container. 

Het is maar op het moment dat we dit standaard run commando beginnen aanpassen met opties dat er enkele dingen zijn waarvoor we best opletten. Wanneer een docker run commando wordt uitgevoerd zijn er twee dingen die we in opties kunnen toevoegen waar we toch iets voorzichtiger mee moeten zijn. Namelijk netwerk configuratie en mounts van host directories in de container.

Netwerk configuratie van docker is als er niets aan is aangepast tameliljk robuust. Maar als we hierin dingen beginnen aanpassen is het mogelijk om deze rubuustheid wat te ondermijnen. Een van de elementen hierbij is poorten. Bij het connecteren naar buiten de machine waarop een container opereert moet een zowel een poort op de host als op de container worden opengesteld, waarna deze poorten "verbonden worden" waardoor het netwerkverkeer die op de gedefinieërde poort van de host toekomt wordt doorgezonden naar de gekozen poort op de container. Een best practice hierbij is om altijd de volledige connectie te definiëren, dit wil zeggen dat we zowel de de enxterne interface, de externe host poort als de interne container poort meegeven met ons run commando. Hierbij worden op de container best enkel poorten geopend die effectief gebruikt worden door deze container. Dit verkleind het aanvalsvlak via netwerk op deze container. TCP/IP poorten onder 1024 op de host machine worden best ook vermeden om op te binden. Uiteraard zijn er services die hier op moeten binden zoals een http proxy moet luisteren op poort 80 om te kunnen functioneren en zijn ook veilier als ze hierop luisteren. Een goede maatstaf om te weten als een container op een privileged port gebonden moet worden is kijken indien men de service die in de container draait ook wanneer die op een virtuele machine draait op een poort onder 1024 zou binden. Daarnaast hebben we net zoals bij Kernel Capabilities ook bij netwerking ook een manier om het intern Docker netwerk te omzeilen. Een container gebruikt standaard een bridged netwerk, hierdoor wordt deze container in een aparte netwerk stack gestoken. Als we de optie ´--net=host´ meegeven overriden we dit en geven we de container toegang tot alle netwerk interfaces van de host machine. Dit moet tenzij in zeer specifieke toepassingen niet gebrijkt worden.


%TODO Mounting van directories
\subsection{container configuratie}

Om extra beveiliging te voorzien voor de docker containers is het mogelijk (indien ondersteund door de host OS) om AppArmor en SeLinux te gebruiken. Met AppArmor is het mogelijk om voor elke container appart een AppArmor profiel te maken. SeLinux voor docker moet aangezet worden bij het opstarten van de Docker Daemon, dit kan simpel gedaan worden door de Daemon bij het starten de optie ´--selinux-enabled´ mee te geven. Hierna kunnen we SeLinux security opties meegeven aan containers. Zowel AppArmor en Selinux zorgen ervoor dat we elke container individueel kunnen configureren op vlak van security. Het individueel configureren van SeLinux en AppArmor voor containers kan vergeleken worden met het configureren voor processen op een niet-Docker systeem. Dit is buiten de scope van deze Bachelorproef en hierom gaan we hier niet verder op in.

Daarnaast is een element die we moeten bekijken wat we nu precies in een container willen draaien qua processen. Het idee achter docker is om één enkele applicatie per container op te delen. Docker luistert standaard enkel op één hoofdprocess, dus indien we meerdere processen willen uitvoeren op 1 container die niet gemaakt zijn om vanuit 1 hoofdprocess op te starten en informatie terug door te geven via dit hoofd process moeten we een process manager gaan bijvoegen in de container. Dit zorgt er onder andere voor dat een container die algemeen gezien een simpel iets is weer zeer complex wordt. Anderzijds zorgt dit ervoor dat je de processen binnen de container niet meer op een optimale monier kunt monitoren met docker. Een voorbeeld hiervan zou zijn indien we zowel onze applicatie als de database op eenzelfde container plaatsen. Inden we deze configuratie zouden gebruiken merken we al snel dat het heel wat makkelijker zou zijn op elke vlak om gewoon de database uit de applicatie container te halen en in zijn eigen container op te starten, dit heeft ons naast een robuuster systeem (als de applicatie crasht zou het kunnen dat ditde database mee doet crashen indien het op dezelfde container draait) ook een meer schaalbaar systeem door gewoon meer applicatie containers te linken met dezelfde database container. Een ander voorbeeld is het gebruik van SSH, container hebben in de meeste gevallen geen ssh nodig. Alle containers zijn toegankelijk via het hostsysteem met het commando ´docker exec CONTAINER´ dus is daar de meest aangewezen plaats om SSH te installeren.
